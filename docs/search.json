[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Literacy",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "narrative_BasicDataTypes.html",
    "href": "narrative_BasicDataTypes.html",
    "title": "1  Basic Data Types",
    "section": "",
    "text": "Photo by Matt J_Cand on Unsplash"
  },
  {
    "objectID": "narrative_BasicDataTypes.html#missing-data",
    "href": "narrative_BasicDataTypes.html#missing-data",
    "title": "1  Basic Data Types",
    "section": "1.1 Missing Data",
    "text": "1.1 Missing Data\n\nThe Absence of Data\n\nThe most fundamental type of data in R is data that does not exist! Missing data! It is represented as NA\n\nx <- NA\n\nand can be in"
  },
  {
    "objectID": "narrative_BasicDataTypes.html#numerical-data",
    "href": "narrative_BasicDataTypes.html#numerical-data",
    "title": "1  Basic Data Types",
    "section": "1.2 Numerical Data",
    "text": "1.2 Numerical Data\n\nNumerical data contains all numerical represenations.\n\nBy far, the most common kind of data we use in our analyses is numerical data. This may represent measured things like height, snout-vent length (whatever that is), depth, age, etc. In data analysis, we commonly take (or obtain) measurements from several items and then try to characterize them using summaries and visualization.\nIn R, the numerical data type can be defined as:\n\nX <- 42\n\nNotice how the numerical value of 42 is assigned to the variable named X. To have R print out the value of a particular variable, you can type its name in the console and it will give it to you.\n\nX\n\n[1] 42\n\n\n\n1.2.1 Operators\nNumeric types have a ton of normal operators that can be used. Some examples include:\nThe usual arithmatic operators:\n\nx <- 10\ny <- 23\n\nx + y\n\n[1] 33\n\nx - y\n\n[1] -13\n\nx * y\n\n[1] 230\n\nx / y\n\n[1] 0.4347826\n\n\nYou have the exponentials:\n\n## x raised to the y\nx^y\n\n[1] 1e+23\n\n## the inverse of an exponent is a root, here is the 23rd root of 10\nx^(1/y)\n\n[1] 1.105295\n\n\nThe logrithmics:\n\n## the natural log\nlog(x)\n\n[1] 2.302585\n\n## Base 10 log\nlog(x,base=10)\n\n[1] 1\n\n\nAnd the modulus operator:\n\ny %% x\n\n[1] 3\n\n\nIf you didn’t know what this one is, don’t worry. The modulus is just the remainder after division like you did in grade school. The above code means that 23 divided by 10 has a remainder of 3. I include it here just to highlight the fact that many of the operators that we will be working with in R are created by more than just a single symbol residing at the top row of your computer keyboard. There are just too few symbos on the normal keyboard to represent the breath of operators. The authors of R have decided that using combinations of symbols to handle these and you will get used to them in not time at all.\n\n\n1.2.2 Introspection & Coercion\nThe class() of a numeric type is (wait for it)… numeric (those R programmers are sure clever).\n\nclass( 42 )\n\n[1] \"numeric\"\n\n\n\nIn this case class is the name of the function and there are one or more things we pass to that function. These must be enclosed in the parenthesis associated with class. The parantheses must be right next to the name of the function. If you put a space betwen the word class and the parentheses, it may not work the way you would like it to. You’ve been warned.\nThe stuff inside the parenthesis are called arguments and are the data that we pass to the function itself. In this case we pass a value or varible to the class function and it does its magic and tells us what kind of data type it is. Many functions have several arguements that can be passed to them, some optional, some not. We will get more into that on the lecture covering Functions.\n\nIt is also possible to inquire if a particular variable is of a certain class. This is done by using the is.* set of functions.\n\nis.numeric( 42 )\n\n[1] TRUE\n\nis.numeric( \"dr dyer\" )\n\n[1] FALSE\n\n\nSometimes we may need to turn one kind of class into another kind. Consider the following:\n\nx <- \"42\"\nis.numeric( x )\n\n[1] FALSE\n\nclass(x)\n\n[1] \"character\"\n\n\nIt is a character data type because it is enclosed within a set of quotes. However, we can coerce it into a numeric type by:\n\ny <- as.numeric( x )\nis.numeric( y )\n\n[1] TRUE\n\ny\n\n[1] 42"
  },
  {
    "objectID": "narrative_BasicDataTypes.html#character-data",
    "href": "narrative_BasicDataTypes.html#character-data",
    "title": "1  Basic Data Types",
    "section": "1.3 Character Data",
    "text": "1.3 Character Data\n\nCharacter data represents textual content.\n\nThe data type character is intended to represent textual data such as actual texts, names of objects, and other contnet that is intended to help both you and the audience you are trying to reach better understand your data.\n\nname <- \"Dyer\"\nsport <- \"Frolf\"\n\nThe two variables above have a sequence of characters enclosed by a double quote. You can use a single quote instead, however the enclosing quoting characters must be the same (e.g., you cannot start with a single quote and end with a double).\n\n1.3.1 Lengths\nThe length of a string is a measure of how many varibles there are, not the number of characters within it. For example, the length of dyer is\n\nlength(name)\n\n[1] 1\n\n\nbecause it only has one character but the number of characters within it is:\n\nnchar(name)\n\n[1] 4\n\n\nLength is defined specifically on the number of elements in a vector, and technically the variable dyer is a vector of length one. If we concatinate them into a vector (go see the vector content)\n\nphrase <- c( name, sport )\n\nwe find that it has a length of 2\n\nlength(phrase)\n\n[1] 2\n\n\nAnd if we ask the vector how many characters are in the elements it contains, it gives us a vector of numeric types representing the number of letters in each of the elements.\n\nnchar(phrase)\n\n[1] 4 5\n\n\n\n\n1.3.2 Putting Character Objects Together\nThe binary + operator has not been defined for objects of class character, which is understandable once we consider all the different ways we may want to put the values contained in the variables together. If you try it, R will complain.\n\nname + sport\n\nError in name + sport: non-numeric argument to binary operator\n\n\nThe paste() function is designed to take a collection of character variables and smush them togethers. By default, it inserts a space between each of the variables and/or values passed to it.\n\npaste( name, \"plays\", sport )\n\n[1] \"Dyer plays Frolf\"\n\n\nAlthough, you can have any kind of separator you like:\n\npaste(name, sport, sep=\" is no good at \")\n\n[1] \"Dyer is no good at Frolf\"\n\n\nThe elements you pass to paste() do not need to be held in variables, you can put quoted character values in there as well.\n\npaste( name, \" the \", sport, \"er\", sep=\"\") \n\n[1] \"Dyer the Frolfer\"\n\n\nIf you have a vector of character types, by default, it considers the pasting operation to be applied to every element of the vector.\n\npaste( phrase , \"!\")\n\n[1] \"Dyer !\"  \"Frolf !\"\n\n\nHowever if you intention is to take the elements of the vector and paste them together, then you need to specify that using the collapse optional argument. By default, it is set to NULL, and that state tells the function to apply the paste()-ing to each element. However, if you set collapse to something other than NULL, it will use that to take all the elements and put them into a single response.\n\npaste( phrase, collapse = \" is not good at \") \n\n[1] \"Dyer is not good at Frolf\"\n\n\n\n\n1.3.3 String Operations\nMany times, we need to extract components from within a longer character element. Here is a longer bit of text as an example.\n\ncorpus <- \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in California, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the California Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\n\n1.3.4 Splits\nWe can split the original string into several components by specifying which particular character or set of characters we wish to use to break it apart.\nAs we start working with increasingly more complicated string operations, I like to use a higher-level library (part of tidyverse) called stringr. If you do not have this library already installed, you can install it using install.packages(\"stringr\").\n\nlibrary( stringr )\n\nHere is an example using the space character to pull it apart into words.\n\nstr_split( corpus, pattern=\" \", simplify=TRUE)\n\n     [,1] [,2]            [,3]     [,4]        [,5]     [,6]    [,7]    \n[1,] \"An\" \"environmental\" \"impact\" \"statement\" \"(EIS),\" \"under\" \"United\"\n     [,8]     [,9]            [,10]  [,11] [,12] [,13]      [,14]      [,15]\n[1,] \"States\" \"environmental\" \"law,\" \"is\"  \"a\"   \"document\" \"required\" \"by\" \n     [,16] [,17]  [,18]      [,19]           [,20]    [,21] [,22]    [,23]\n[1,] \"the\" \"1969\" \"National\" \"Environmental\" \"Policy\" \"Act\" \"(NEPA)\" \"for\"\n     [,24]     [,25]     [,26]            [,27]       [,28] [,29]     [,30]\n[1,] \"certain\" \"actions\" \"'significantly\" \"affecting\" \"the\" \"quality\" \"of\" \n     [,31] [,32]   [,33]              [,34] [,35] [,36] [,37] [,38]  [,39]\n[1,] \"the\" \"human\" \"environment'.[1]\" \"An\"  \"EIS\" \"is\"  \"a\"   \"tool\" \"for\"\n     [,40]      [,41]     [,42] [,43]       [,44] [,45]      [,46] [,47]     \n[1,] \"decision\" \"making.\" \"It\"  \"describes\" \"the\" \"positive\" \"and\" \"negative\"\n     [,48]           [,49]     [,50] [,51] [,52]      [,53]     [,54] [,55]\n[1,] \"environmental\" \"effects\" \"of\"  \"a\"   \"proposed\" \"action,\" \"and\" \"it\" \n     [,56]     [,57]  [,58]   [,59] [,60] [,61]  [,62]         [,63]     [,64] \n[1,] \"usually\" \"also\" \"lists\" \"one\" \"or\"  \"more\" \"alternative\" \"actions\" \"that\"\n     [,65] [,66] [,67]    [,68]     [,69] [,70] [,71]    [,72]       [,73]\n[1,] \"may\" \"be\"  \"chosen\" \"instead\" \"of\"  \"the\" \"action\" \"described\" \"in\" \n     [,74] [,75]  [,76]     [,77]  [,78]   [,79]         [,80]     [,81]  [,82]\n[1,] \"the\" \"EIS.\" \"Several\" \"U.S.\" \"state\" \"governments\" \"require\" \"that\" \"a\"  \n     [,83]      [,84]     [,85] [,86] [,87] [,88] [,89]       [,90] [,91]\n[1,] \"document\" \"similar\" \"to\"  \"an\"  \"EIS\" \"be\"  \"submitted\" \"to\"  \"the\"\n     [,92]   [,93] [,94]     [,95]      [,96] [,97]      [,98] [,99]        \n[1,] \"state\" \"for\" \"certain\" \"actions.\" \"For\" \"example,\" \"in\"  \"California,\"\n     [,100] [,101]          [,102]   [,103]   [,104]  [,105] [,106] [,107]     \n[1,] \"an\"   \"Environmental\" \"Impact\" \"Report\" \"(EIR)\" \"must\" \"be\"   \"submitted\"\n     [,108] [,109] [,110]  [,111] [,112]    [,113]     [,114] [,115]     \n[1,] \"to\"   \"the\"  \"state\" \"for\"  \"certain\" \"actions,\" \"as\"   \"described\"\n     [,116] [,117] [,118]       [,119]          [,120]    [,121] [,122]   \n[1,] \"in\"   \"the\"  \"California\" \"Environmental\" \"Quality\" \"Act\"  \"(CEQA).\"\n     [,123] [,124] [,125] [,126]    [,127]    [,128] [,129] [,130] [,131]\n[1,] \"One\"  \"of\"   \"the\"  \"primary\" \"authors\" \"of\"   \"the\"  \"act\"  \"is\"  \n     [,132]   [,133] [,134]     \n[1,] \"Lynton\" \"K.\"   \"Caldwell.\"\n\n\nwhich shows 134 words in the text.\nI need to point out that I added the simplify=TRUE option to str_split. Had I not done that, it would have returned a list object that contained the individual vector of words. There are various reasons that it returns a list, none of which I can frankly understand, that is just the way the authors of the function made it.\n\n\n1.3.5 Substrings\nThere are two different things you may want to do with substrings; find them and replace them. Here are some ways to figure out where they are.\n\nstr_detect(corpus, \"Environment\")\n\n[1] TRUE\n\n\n\nstr_count( corpus, \"Environment\")\n\n[1] 3\n\n\n\nstr_locate_all( corpus, \"Environment\")\n\n[[1]]\n     start end\n[1,]   125 135\n[2,]   637 647\n[3,]   754 764\n\n\nWe can also replace instances of one substring with another.\n\nstr_replace_all(corpus, \"California\", \"Virginia\")\n\n[1] \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in Virginia, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the Virginia Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\nThere is a lot more fun stuff to do with string based data."
  },
  {
    "objectID": "narrative_BasicDataTypes.html#logical-data",
    "href": "narrative_BasicDataTypes.html#logical-data",
    "title": "1  Basic Data Types",
    "section": "1.4 Logical Data",
    "text": "1.4 Logical Data\nLogical data consists of two mutually exclusive states: TRUE or FALSE\n \n\ndyer_has_good_jokes <- TRUE\ndyer_has_good_jokes\n\n[1] TRUE\n\n\n\n1.4.1 Operators on Logical Types\nThere are 3 primary logical operators that can be used on logical types; one unary and two binary.\n \n\n1.4.1.1 Unary Operator\nThe negation operator\n\n!dyer_has_good_jokes\n\n[1] FALSE\n\n\n \n\n\n\n1.4.2 The Binary Operators\n\n1.4.2.1 The OR operator\n\nTRUE | FALSE\n\n[1] TRUE\n\n\n\n\n1.4.2.2 The AND operator\n\nTRUE & FALSE\n\n[1] FALSE\n\n\n\n\n\n1.4.3 Introspection\nLogical types have an introspection operator.\n \n\nis.logical( dyer_has_good_jokes )\n\n[1] TRUE\n\n\nCoercion of something else to a Logical is more case-specific.\nFrom character data.\n\nas.logical( \"TRUE\" )\n\n[1] TRUE\n\n\n\nas.logical( \"FALSE\" )\n\n[1] FALSE\n\n\nOther character types result in NA (missing data).\n\nas.logical( \"Bob\" )\n\n[1] NA\n\n\n\n\n1.4.4 Coercion\nCoercion of something else to a Logical is more case-specific.\n \nFrom numeric data:\n- Values of 0 are FALSE\n- Non-zero values are TRUE\n\nas.logical(0)\n\n[1] FALSE\n\n\n\nas.logical( 323 )\n\n[1] TRUE"
  },
  {
    "objectID": "narrative_BasicDataTypes.html#dates",
    "href": "narrative_BasicDataTypes.html#dates",
    "title": "1  Basic Data Types",
    "section": "1.5 Dates",
    "text": "1.5 Dates\n\nTime is the next dimension.\n\nThis topic covers the basics of how we put together data based upon date and time objects. For this, we will use the following data frame with a single column of data representing dates as they are written in the US.\nThese are several challenges associated with working with date and time objects. To those of us who are reading this with a background of how US time and date formats are read, we can easily interpret data objects as Month/Day/Year formats (e.g., “2/14/2018”), and is commonly represented in the kind of input data we work in R with as a string of characters. Dates and times are sticky things in data analysis because they do not work the way we think they should. Here are some wrinkles:\n\nThere are many types of calendars, we use the Julian calendar. However, there are many other calendars that are in use that we may run into. Each of these calendars has a different starting year (e.g., in the Assyrian calendar it is year 6770, it is 4718 in the Chinese calendar, 2020 in the Gregorian, and 1442 in the Islamic calendar).\nWestern calendar has leap years (+1 day in February) as well as leap seconds because it is based on the rotation around the sun, others are based upon the lunar cycle and have other corrections.\nOn this planet, we have 24 different time zones. Some states (looking at you Arizona) don’t feel it necessary to follow the other states around so they may be the same as PST some of the year and the same as MST the rest of the year. The provence of Newfoundland decided to be half-way between time zones so they are GMT-2:30. Some states have more than one time zone even if they are not large in size (hello Indiana).\nDates and time are made up of odd units, 60-seconds a minute, 60-minutes an hour, 24-hours a day, 7-days a week, 2-weeks a fortnight, 28,29,30,or 31-days in a month, 365 or 366 days in a year, 100 years in a century, etc.\n\nFortunately, some smart programmers have figured this out for us already. What they did is made the second as the base unit of time and designated 00:00:00 on 1 January 1970 as the unix epoch. Time on most modern computers is measured from that starting point. It is much easier to measure the difference between two points in time using the seconds since unix epich and then translate it into one or more of these calendars than to deal with all the different calendars each time. So under the hood, much of the date and time issues are kept in terms of epoch seconds.\n\nunclass( Sys.time() )\n\n[1] 1670523351\n\n\n\n1.5.1 Basic Date Objects\nR has some basic date functionality built into it. One of the easiest ways to get a date object created is to specify the a date as a character string and then coerce it into a data object. By default, this requires us to represent the date objects as “YEAR-MONTH-DAY” with padding 0 values for any integer of month or date below 9 (e.g., must be two-digits).\nSo for example, we can specify a date object as:\n\nclass_start <- as.Date(\"2021-01-15\")\nclass_start\n\n[1] \"2021-01-15\"\n\n\nAnd it is of type:\n\nclass( class_start )\n\n[1] \"Date\"\n\n\nIf you want to make a date from a different format, you need to specify what elements within the string representation using format codes. These codes (and many more) can be found by looking at ?strptime.\n\nclass_end <- as.Date( \"5/10/21\", format = \"%m/%d/%y\")\nclass_end\n\n[1] \"2021-05-10\"\n\n\nI like to use some higher-level date functions from the lubridate library. If you don’t have it installed, do so using the normal approach.\n\nlibrary( lubridate )\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nDate objects can be put into vectors and sequences just like other objects.\n\nsemester <- seq( class_start, class_end, by = \"1 day\")\nsemester\n\n  [1] \"2021-01-15\" \"2021-01-16\" \"2021-01-17\" \"2021-01-18\" \"2021-01-19\"\n  [6] \"2021-01-20\" \"2021-01-21\" \"2021-01-22\" \"2021-01-23\" \"2021-01-24\"\n [11] \"2021-01-25\" \"2021-01-26\" \"2021-01-27\" \"2021-01-28\" \"2021-01-29\"\n [16] \"2021-01-30\" \"2021-01-31\" \"2021-02-01\" \"2021-02-02\" \"2021-02-03\"\n [21] \"2021-02-04\" \"2021-02-05\" \"2021-02-06\" \"2021-02-07\" \"2021-02-08\"\n [26] \"2021-02-09\" \"2021-02-10\" \"2021-02-11\" \"2021-02-12\" \"2021-02-13\"\n [31] \"2021-02-14\" \"2021-02-15\" \"2021-02-16\" \"2021-02-17\" \"2021-02-18\"\n [36] \"2021-02-19\" \"2021-02-20\" \"2021-02-21\" \"2021-02-22\" \"2021-02-23\"\n [41] \"2021-02-24\" \"2021-02-25\" \"2021-02-26\" \"2021-02-27\" \"2021-02-28\"\n [46] \"2021-03-01\" \"2021-03-02\" \"2021-03-03\" \"2021-03-04\" \"2021-03-05\"\n [51] \"2021-03-06\" \"2021-03-07\" \"2021-03-08\" \"2021-03-09\" \"2021-03-10\"\n [56] \"2021-03-11\" \"2021-03-12\" \"2021-03-13\" \"2021-03-14\" \"2021-03-15\"\n [61] \"2021-03-16\" \"2021-03-17\" \"2021-03-18\" \"2021-03-19\" \"2021-03-20\"\n [66] \"2021-03-21\" \"2021-03-22\" \"2021-03-23\" \"2021-03-24\" \"2021-03-25\"\n [71] \"2021-03-26\" \"2021-03-27\" \"2021-03-28\" \"2021-03-29\" \"2021-03-30\"\n [76] \"2021-03-31\" \"2021-04-01\" \"2021-04-02\" \"2021-04-03\" \"2021-04-04\"\n [81] \"2021-04-05\" \"2021-04-06\" \"2021-04-07\" \"2021-04-08\" \"2021-04-09\"\n [86] \"2021-04-10\" \"2021-04-11\" \"2021-04-12\" \"2021-04-13\" \"2021-04-14\"\n [91] \"2021-04-15\" \"2021-04-16\" \"2021-04-17\" \"2021-04-18\" \"2021-04-19\"\n [96] \"2021-04-20\" \"2021-04-21\" \"2021-04-22\" \"2021-04-23\" \"2021-04-24\"\n[101] \"2021-04-25\" \"2021-04-26\" \"2021-04-27\" \"2021-04-28\" \"2021-04-29\"\n[106] \"2021-04-30\" \"2021-05-01\" \"2021-05-02\" \"2021-05-03\" \"2021-05-04\"\n[111] \"2021-05-05\" \"2021-05-06\" \"2021-05-07\" \"2021-05-08\" \"2021-05-09\"\n[116] \"2021-05-10\"\n\n\nSome helpful functions include the Julian Ordinal Day (e.g., number of days since the start of the year).\n\nordinal_day <- yday( semester[102] )\nordinal_day\n\n[1] 116\n\n\nThe weekday as an integer (0-6 starting on Sunday), which I use to index the named values.\n\ndays_of_week <- c(\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\")\nx <- wday( semester[32] )\ndays_of_week[ x ]\n\n[1] \"Monday\"\n\n\nSince we did not specify a time, things like hour() and minute() do not provide any usable information.\n\n\n1.5.2 Dates & Times\nTo add time to the date objects, we need to specify both date and time specifically. Here are some example data:\n\ndf <- data.frame( Date = c(\"8/21/2004 7:33:51 AM\",\n                           \"7/12/2008 9:23:08 PM\",\n                           \"2/14/2010 8:18:30 AM\",\n                           \"12/23/2018 11:11:45 PM\",\n                           \"2/1/2019 4:42:00 PM\",\n                           \"5/17/2012 1:23:23 AM\",\n                           \"12/11/2020 9:48:02 PM\") )\nsummary( df )\n\n     Date          \n Length:7          \n Class :character  \n Mode  :character  \n\n\nJust like above, if we want to turn these into date and time objects we must be able to tell the parsing algorithm what elements are represented in each entry. There are many ways to make dates and time, 10/14 or 14 Oct or October 14 or Julian day 287, etc. These are designated by a format string were we indicate what element represents a day or month or year or hour or minute or second, etc. These are found by looking at the documentation for?strptime.\nIn our case, we have:\n- Month as 1 or 2 digits\n- Day as 1 or 2 digits\n- Year as 4 digits\n- a space to separate date from time\n- hour (not 24-hour though)\n- minutes in 2 digits\n- seconds in 2 digits\n- a space to separate time from timezone\n- timezone\n- / separating date objects\n- : separating time objects\nTo make the format string, we need to look up how to encode these items. The items in df for a date & time object such as 2/1/2019 4:42:00 PM have the format string:\n\nformat <- \"%m/%d/%Y %I:%M:%S %p\"\n\nNow, we can convert the character string in the data frame to a date and time object.\n\n\n1.5.3 Lubridate\nInstead of using the built-in as.Date() functionality, I like the lubridate library1 as it has a lot of additional functionality that we’ll play with a bit later.\n\ndf$Date <- parse_date_time( df$Date, \n                            orders=format, \n                            tz = \"EST\" )\nsummary( df )\n\n      Date                       \n Min.   :2004-08-21 07:33:51.00  \n 1st Qu.:2009-04-29 14:50:49.00  \n Median :2012-05-17 01:23:23.00  \n Mean   :2013-07-11 07:28:39.85  \n 3rd Qu.:2019-01-12 19:56:52.50  \n Max.   :2020-12-11 21:48:02.00  \n\nclass( df$Date )\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\nNow, we can ask Date-like questions about the data such as what day of the week was the first sample taken?\n\nweekdays( df$Date[1] )\n\n[1] \"Saturday\"\n\n\nWhat is the range of dates?\n\nrange( df$Date )\n\n[1] \"2004-08-21 07:33:51 EST\" \"2020-12-11 21:48:02 EST\"\n\n\nWhat is the median of samples\n\nmedian( df$Date )\n\n[1] \"2012-05-17 01:23:23 EST\"\n\n\nand what julian ordinal day (e.g., how many days since start of the year) is the last record.\n\nyday( df$Date[4] )\n\n[1] 357\n\n\nJust for fun, I’ll add a column to the data that has weekday.\n\ndf$Weekday <- weekdays( df$Date )\ndf\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n5 2019-02-01 16:42:00   Friday\n6 2012-05-17 01:23:23 Thursday\n7 2020-12-11 21:48:02   Friday\n\n\nHowever, we should probably turn it into a factor (e.g., a data type with pre-defined levels—and for us here—an intrinsic order of the levels).\n\ndf$Weekday <- factor( df$Weekday, \n                        ordered = TRUE, \n                        levels = days_of_week\n                        )\nsummary( df$Weekday )\n\n   Sunday    Monday   Tuesday Wednesday  Thursday    Friday  Saturday \n        2         0         0         0         1         2         2 \n\n\n\n\n1.5.4 Filtering on Date Objects\nWe can easily filter the content within a data.frame using some helper functions such as hour(), minute(), weekday(), etc. Here are some examples including pulling out the weekends.\n\nweekends <- df[ df$Weekday %in% c(\"Saturday\",\"Sunday\"), ]\nweekends\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n\n\nfinding items that are in the past (paste being defined as the last time this document was knit).\n\npast <- df$Date[ df$Date < Sys.time() ]\npast\n\n[1] \"2004-08-21 07:33:51 EST\" \"2008-07-12 21:23:08 EST\"\n[3] \"2010-02-14 08:18:30 EST\" \"2018-12-23 23:11:45 EST\"\n[5] \"2019-02-01 16:42:00 EST\" \"2012-05-17 01:23:23 EST\"\n[7] \"2020-12-11 21:48:02 EST\"\n\n\nItems that are during working hours\n\nwork <- df$Date[ hour(df$Date) >= 9 & hour(df$Date) <= 17 ]\nwork\n\n[1] \"2019-02-01 16:42:00 EST\"\n\n\nAnd total range of values in days using normal arithmatic operations such as the minus operator.\n\nmax(df$Date) - min(df$Date)\n\nTime difference of 5956.593 days"
  },
  {
    "objectID": "narrative_BasicDataTypes.html#questions",
    "href": "narrative_BasicDataTypes.html#questions",
    "title": "1  Basic Data Types",
    "section": "1.6 Questions",
    "text": "1.6 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas."
  },
  {
    "objectID": "narrative_Factors.html",
    "href": "narrative_Factors.html",
    "title": "2  Factor Data",
    "section": "",
    "text": "Photo by Paolo Bendandi on Unsplash"
  },
  {
    "objectID": "narrative_Factors.html#factors",
    "href": "narrative_Factors.html#factors",
    "title": "2  Factor Data",
    "section": "2.1 Factors",
    "text": "2.1 Factors\nI’m going to start with some days of the week because they are exclusive (e.g., you cannot be in both Monday and Wednesday at the same time). Factors are initially created from string objects, though you could use numeric data but that would be stupid because you should use things that are descriptive and strings are much better than that.\n\nweekdays <- c(\"Monday\",\"Tuesday\",\"Wednesday\",\n              \"Thursday\",\"Friday\",\"Saturday\", \n              \"Sunday\")\nclass( weekdays )\n\n[1] \"character\"\n\n\nI’m going to take these days and random sample them to create a vector of 40 elements. This is something we do all the time and there is a sample() function that allows us to draw random samples either with or without replacement (e.g., can you select the same value more than once).\n\ndata <- sample( weekdays, size=40, replace=TRUE)\ndata\n\n [1] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Friday\"    \"Friday\"    \"Saturday\" \n [7] \"Monday\"    \"Saturday\"  \"Friday\"    \"Tuesday\"   \"Thursday\"  \"Wednesday\"\n[13] \"Sunday\"    \"Tuesday\"   \"Monday\"    \"Wednesday\" \"Sunday\"    \"Monday\"   \n[19] \"Friday\"    \"Friday\"    \"Saturday\"  \"Sunday\"    \"Tuesday\"   \"Tuesday\"  \n[25] \"Sunday\"    \"Sunday\"    \"Monday\"    \"Wednesday\" \"Monday\"    \"Friday\"   \n[31] \"Saturday\"  \"Saturday\"  \"Wednesday\" \"Saturday\"  \"Thursday\"  \"Monday\"   \n[37] \"Sunday\"    \"Friday\"    \"Thursday\"  \"Friday\"   \n\n\nThese data are still\n\nclass( data )\n\n[1] \"character\"\n\n\nTo turn them into a factor, we use…. factor()\n\ndays <- factor( data )\nis.factor( days )\n\n[1] TRUE\n\nclass( days )\n\n[1] \"factor\"\n\n\nNow when we look at the data, it looks a lot like it did before except for the last line which shows you the unique levels for elements in the vector.\n\ndays\n\n [1] Friday    Monday    Tuesday   Friday    Friday    Saturday  Monday   \n [8] Saturday  Friday    Tuesday   Thursday  Wednesday Sunday    Tuesday  \n[15] Monday    Wednesday Sunday    Monday    Friday    Friday    Saturday \n[22] Sunday    Tuesday   Tuesday   Sunday    Sunday    Monday    Wednesday\n[29] Monday    Friday    Saturday  Saturday  Wednesday Saturday  Thursday \n[36] Monday    Sunday    Friday    Thursday  Friday   \nLevels: Friday Monday Saturday Sunday Thursday Tuesday Wednesday\n\nsummary( days )\n\n   Friday    Monday  Saturday    Sunday  Thursday   Tuesday Wednesday \n        9         7         6         6         3         5         4 \n\n\nWe can put them into data frames and they know how to summarize themselves properly by counting the number of occurances of each level.\n\ndf <- data.frame( ID = 1:40, Weekdays = days )\nsummary( df )\n\n       ID             Weekdays\n Min.   : 1.00   Friday   :9  \n 1st Qu.:10.75   Monday   :7  \n Median :20.50   Saturday :6  \n Mean   :20.50   Sunday   :6  \n 3rd Qu.:30.25   Thursday :3  \n Max.   :40.00   Tuesday  :5  \n                 Wednesday:4  \n\n\nAnd we can directly access the unique levels\n\nlevels( days )\n\n[1] \"Friday\"    \"Monday\"    \"Saturday\"  \"Sunday\"    \"Thursday\"  \"Tuesday\"  \n[7] \"Wednesday\"\n\n\nSo factors can be categorical (e.g., one is just different than the next) and compared via == and != values. Or they can be ordinal such that > and < make sense.\nBy default, a factor is not ordered.\n\nis.ordered( days )\n\n[1] FALSE\n\ndays[1] < days[2]\n\nWarning in Ops.factor(days[1], days[2]): '<' not meaningful for factors\n\n\n[1] NA\n\n\n\ndata <- factor( days, ordered=TRUE )\ndata \n\n [1] Friday    Monday    Tuesday   Friday    Friday    Saturday  Monday   \n [8] Saturday  Friday    Tuesday   Thursday  Wednesday Sunday    Tuesday  \n[15] Monday    Wednesday Sunday    Monday    Friday    Friday    Saturday \n[22] Sunday    Tuesday   Tuesday   Sunday    Sunday    Monday    Wednesday\n[29] Monday    Friday    Saturday  Saturday  Wednesday Saturday  Thursday \n[36] Monday    Sunday    Friday    Thursday  Friday   \n7 Levels: Friday < Monday < Saturday < Sunday < Thursday < ... < Wednesday\n\n\nSo that if we go and try to order them, the only way they can be sorted is alphabetically.\n\nsort( data )\n\n [1] Friday    Friday    Friday    Friday    Friday    Friday    Friday   \n [8] Friday    Friday    Monday    Monday    Monday    Monday    Monday   \n[15] Monday    Monday    Saturday  Saturday  Saturday  Saturday  Saturday \n[22] Saturday  Sunday    Sunday    Sunday    Sunday    Sunday    Sunday   \n[29] Thursday  Thursday  Thursday  Tuesday   Tuesday   Tuesday   Tuesday  \n[36] Tuesday   Wednesday Wednesday Wednesday Wednesday\n7 Levels: Friday < Monday < Saturday < Sunday < Thursday < ... < Wednesday\n\n\nHowever, this does not make sense. Who in their right mind would like to have Friday followed immediately by Monday? That is just not right!\nTo establish an ordinal variable with a specified sequence of values that are not alphabetical we need to pass along the levels themselves.\n\ndata <- factor( days, ordered=TRUE, levels = weekdays )\ndata\n\n [1] Friday    Monday    Tuesday   Friday    Friday    Saturday  Monday   \n [8] Saturday  Friday    Tuesday   Thursday  Wednesday Sunday    Tuesday  \n[15] Monday    Wednesday Sunday    Monday    Friday    Friday    Saturday \n[22] Sunday    Tuesday   Tuesday   Sunday    Sunday    Monday    Wednesday\n[29] Monday    Friday    Saturday  Saturday  Wednesday Saturday  Thursday \n[36] Monday    Sunday    Friday    Thursday  Friday   \n7 Levels: Monday < Tuesday < Wednesday < Thursday < Friday < ... < Sunday\n\n\nNow they’ll sort properly.\n\nsort( data )\n\n [1] Monday    Monday    Monday    Monday    Monday    Monday    Monday   \n [8] Tuesday   Tuesday   Tuesday   Tuesday   Tuesday   Wednesday Wednesday\n[15] Wednesday Wednesday Thursday  Thursday  Thursday  Friday    Friday   \n[22] Friday    Friday    Friday    Friday    Friday    Friday    Friday   \n[29] Saturday  Saturday  Saturday  Saturday  Saturday  Saturday  Sunday   \n[36] Sunday    Sunday    Sunday    Sunday    Sunday   \n7 Levels: Monday < Tuesday < Wednesday < Thursday < Friday < ... < Sunday\n\n\n\n2.1.1 Exclusivity of Factor Levels\nOnce you establish a factor, you cannot set the values to anyting that is outside of the pre-defined levels. If you do, it will just put in missing data NA.\n\ndays[3] <- \"Bob\"\n\nWarning in `[<-.factor`(`*tmp*`, 3, value = \"Bob\"): invalid factor level, NA\ngenerated\n\ndays\n\n [1] Friday    Monday    <NA>      Friday    Friday    Saturday  Monday   \n [8] Saturday  Friday    Tuesday   Thursday  Wednesday Sunday    Tuesday  \n[15] Monday    Wednesday Sunday    Monday    Friday    Friday    Saturday \n[22] Sunday    Tuesday   Tuesday   Sunday    Sunday    Monday    Wednesday\n[29] Monday    Friday    Saturday  Saturday  Wednesday Saturday  Thursday \n[36] Monday    Sunday    Friday    Thursday  Friday   \nLevels: Friday Monday Saturday Sunday Thursday Tuesday Wednesday\n\n\nThat being said, we can have more levels in the factor than observed in the data. Here is an example of just grabbing the work days from the week but making the levels equal to all the potential weekdays.\n\nworkdays <- sample( weekdays[1:5], size=40, replace = TRUE )\nworkdays <- factor( workdays, ordered=TRUE, levels = weekdays )\n\nAnd when we summarize it, we see that while it is possible that days may be named Saturday and Sunday, they are not recoreded in the data we have for workdays.\n\nsummary( workdays )\n\n   Monday   Tuesday Wednesday  Thursday    Friday  Saturday    Sunday \n        8        13         4         6         9         0         0 \n\n\nWe can drop the levels that have no representation\n\nworkdays <- droplevels( workdays ) \nsummary( workdays )\n\n   Monday   Tuesday Wednesday  Thursday    Friday \n        8        13         4         6         9"
  },
  {
    "objectID": "narrative_Factors.html#the-forcats-library",
    "href": "narrative_Factors.html#the-forcats-library",
    "title": "2  Factor Data",
    "section": "2.2 The forcats Library",
    "text": "2.2 The forcats Library\nThe forcats library has a bunch of helper functions for working with factors. This is a relatively small library in tidyverse but a powerful one. I would recommend looking at the cheatsheet for it to get a more broad understanding of what functions in this library can do.\n\nlibrary( forcats )\n\nJust like stringr had the str_ prefix, all the functions here have the fct_ prefix. Here are some examples.\nCounting how many of each factor\n\nfct_count( data )\n\n# A tibble: 7 × 2\n  f             n\n  <fct>     <int>\n1 Monday        7\n2 Tuesday       5\n3 Wednesday     4\n4 Thursday      3\n5 Friday        9\n6 Saturday      6\n7 Sunday        6\n\n\nLumping Rare Factors\n\nlumped <- fct_lump_min( data, min = 5 )\nfct_count( lumped )\n\n# A tibble: 6 × 2\n  f            n\n  <fct>    <int>\n1 Monday       7\n2 Tuesday      5\n3 Friday       9\n4 Saturday     6\n5 Sunday       6\n6 Other        7\n\n\nReordering Factor Levels by Frequency\n\nfreq <- fct_infreq( data )\nlevels( freq )\n\n[1] \"Friday\"    \"Monday\"    \"Saturday\"  \"Sunday\"    \"Tuesday\"   \"Wednesday\"\n[7] \"Thursday\" \n\n\nReordering by Order of Appearance\n\nordered <- fct_inorder( data )\nlevels( ordered )\n\n[1] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Saturday\"  \"Thursday\"  \"Wednesday\"\n[7] \"Sunday\"   \n\n\nReordering Specific Levels\n\nnewWeek <- fct_relevel( data, \"Sunday\")\nlevels( newWeek )\n\n[1] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[7] \"Saturday\" \n\n\nDropping Unobserved Levels - just like droplevels()\n\ndropped <- fct_drop( workdays )\nsummary( dropped )\n\n   Monday   Tuesday Wednesday  Thursday    Friday \n        8        13         4         6         9"
  },
  {
    "objectID": "narrative_Factors.html#using-factors",
    "href": "narrative_Factors.html#using-factors",
    "title": "2  Factor Data",
    "section": "2.3 Using Factors",
    "text": "2.3 Using Factors\nIt is common to use factors as an organizing princple in our data. For example, let’s say we went out and sampled three different species of plants and measured characteristics of their flower size. The iris data set from R.A. Fisher is a classid data set that is include in R and it looks like this (the functions head() and tail() show the top or bottom parts of a data frame).\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nBy default it is a data.frame object.\n\nclass( iris )\n\n[1] \"data.frame\"\n\n\n\n2.3.1 By the by\nOne helpful function in base R is the by() function. It has the following form.\nby( data, index, function)\nThe data is the raw data you are using, the index is a vector that we are using to differentiate among the species (the factor), and the function is what function we want to use.\nSo for example, if I were interesed in the mean length of the Sepal for each species, I could write.\n\nmeanSepalLength <- by( iris$Sepal.Length, iris$Species, mean )\nclass( meanSepalLength )\n\n[1] \"by\"\n\nmeanSepalLength\n\niris$Species: setosa\n[1] 5.006\n------------------------------------------------------------ \niris$Species: versicolor\n[1] 5.936\n------------------------------------------------------------ \niris$Species: virginica\n[1] 6.588\n\n\nI could also do the same thing with the variance in sepal length.\n\nby( iris[,2], iris[,5], var ) -> varSepalLength\nvarSepalLength \n\niris[, 5]: setosa\n[1] 0.1436898\n------------------------------------------------------------ \niris[, 5]: versicolor\n[1] 0.09846939\n------------------------------------------------------------ \niris[, 5]: virginica\n[1] 0.1040041\n\n\nUsing these kinds of functions we can create a summary data frame.\n\nlibrary( tidyverse )\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ndf <- tibble( Species = levels( iris$Species), \n              Average = meanSepalLength,\n              Variance = varSepalLength\n)\ndf\n\n# A tibble: 3 × 3\n  Species    Average  Variance  \n  <chr>      <by[1d]> <by[1d]>  \n1 setosa     5.006    0.14368980\n2 versicolor 5.936    0.09846939\n3 virginica  6.588    0.10400408"
  },
  {
    "objectID": "narrative_Factors.html#missing-data",
    "href": "narrative_Factors.html#missing-data",
    "title": "2  Factor Data",
    "section": "2.4 Missing Data",
    "text": "2.4 Missing Data\nMissing data is a .red[fact of life] and R is very opinionated about how it handles missing values. In general, missing data is encoded as NA and is a valid entry for any data type (character, numeric, logical, factor, etc.). Where this becomes tricky is when we are doing operations on data that has missing values. R could take two routes:\n\nIt could ignore the data and give you the answer directly as if the data were not missing, or\n\nIt could let you know that there is missing data and make you do something about it.\n\nFortunately, R took the second route.\nAn example from the iris data, I’m going to add some missing data to it.\n\nmissingIris <- iris[, 4:5]\nmissingIris$Petal.Width[ c(2,6,12) ] <- NA\nsummary( missingIris )\n\n  Petal.Width          Species  \n Min.   :0.100   setosa    :50  \n 1st Qu.:0.300   versicolor:50  \n Median :1.300   virginica :50  \n Mean   :1.218                  \n 3rd Qu.:1.800                  \n Max.   :2.500                  \n NA's   :3                      \n\n\nNotice how the missing data is denoted in the summary.\n\n2.4.1 Indications of Missing Data\nWhen we perform a mathematical or statistical operation on data that has missing elements R will always return NA as the result.\n\nmean( missingIris$Petal.Width )\n\n[1] NA\n\n\nThis warns you that .red[at least one] of the observations in the data is missing.\nSame output for using by(), it will put NA into each level that has at least one missing value.\n\nby( missingIris$Petal.Width, missingIris$Species, mean )\n\nmissingIris$Species: setosa\n[1] NA\n------------------------------------------------------------ \nmissingIris$Species: versicolor\n[1] 1.326\n------------------------------------------------------------ \nmissingIris$Species: virginica\n[1] 2.026\n\n\n\n\n2.4.2 Working with Missing Data\nTo acknowledge that there are missing data and you still want the values, you need to tell the function you are using that data is missing and you are OK with that using the optional argument na.rm=TRUE (na = missing data & rm is remove).\n\nmean( missingIris$Petal.Width, na.rm=TRUE)\n\n[1] 1.218367\n\n\nTo pass this to the by() function, we add the optional argument na.rm=TRUE and by() passes it along to the mean function as “…”\n\nby( missingIris$Petal.Width, missingIris$Species, mean, na.rm=TRUE )\n\nmissingIris$Species: setosa\n[1] 0.2446809\n------------------------------------------------------------ \nmissingIris$Species: versicolor\n[1] 1.326\n------------------------------------------------------------ \nmissingIris$Species: virginica\n[1] 2.026"
  },
  {
    "objectID": "narrative_Factors.html#fancy-tables",
    "href": "narrative_Factors.html#fancy-tables",
    "title": "2  Factor Data",
    "section": "2.5 Fancy Tables",
    "text": "2.5 Fancy Tables\nMaking data frames like that above is a classic maneuver in R and I’m going to use this to introduce the use of the knitr library to show you how to take a set of data and turn it into a table for your manuscript.\n\nlibrary( knitr )\n\nNow we can make a table as:\n\nkable( df )\n\n\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\nWe can even add a caption to it.\n\nirisTable <- kable( df, caption = \"The mean and variance in measured sepal length (in cm) for three species of Iris.\")\nirisTable\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\nIn addition to this basic library, there is an kableExtra one that allows us to get even more fancy. You must go check out this webpage (which is an RMarkdown page by the way) to see all the other ways you can fancy up your tables.\n\nlibrary( kableExtra )\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\n2.5.1 Table Themes\nHere are some examples Themes\n\nkable_paper( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_classic( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_classic_2( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_minimal( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_material( irisTable,lightable_options = c(\"striped\", \"hover\") )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_material_dark( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\n\n2.5.2 Table Sizes and Positions\nWe can be specific about the size and location of the whole table.\n\nkable_paper(irisTable, full_width = FALSE )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\n\nkable_paper( irisTable, full_width=FALSE, position=\"right\")\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\nAnd even embed it in a bunch of text and float it to left or right (I added echo=FALSE to the chunck header so it hides itself).\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Ut blandit libero sit amet porta elementum. In imperdiet tellus non odio porttitor auctor ac sit amet diam. Suspendisse eleifend vel nisi nec efficitur. Ut varius urna lectus, ac iaculis velit bibendum eget. Curabitur dignissim magna eu odio sagittis blandit. Vivamus sed ipsum mi. Etiam est leo, mollis ultrices dolor eget, consectetur euismod augue. In hac habitasse platea dictumst. Integer blandit ante magna, quis volutpat velit varius hendrerit. Vestibulum sit amet lacinia magna. Sed at varius nisl. Donec eu porta tellus, vitae rhoncus velit.\n\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408\n\n\n\n\n\nMaecenas euismod mattis neque. Ut at sapien lacinia, vehicula felis vitae, laoreet odio. Cras ut magna sed sapien scelerisque auctor maximus tincidunt arcu. Praesent vel accumsan leo. Etiam tempor leo placerat, commodo ante eu, posuere ligula. Sed purus justo, feugiat vel volutpat in, faucibus quis sem. Vivamus enim lacus, ultrices id erat in, posuere fringilla est. Nulla porttitor ac nunc nec efficitur. Duis tincidunt metus leo, at lacinia orci tristique in.\nNulla nec elementum nibh, quis congue augue. Vivamus fermentum nec mauris nec vehicula. Proin laoreet sapien quis orci mollis, et condimentum ante tempor. Vivamus hendrerit ut sem a iaculis. Quisque mauris enim, accumsan sit amet fermentum quis, convallis a nisl. Donec elit orci, consectetur id vestibulum in, elementum nec magna. In lobortis erat velit. Nam sit amet finibus arcu.\n\n\n2.5.3 Heading Judo\nWe can do some really cool stuff on row and column headings. Here is an example where I add another row above the data columns for output.\n\nclassic <- kable_paper( irisTable )\n\nWarning in kable_styling(kable_input, \"none\", htmltable_class = light_class, :\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\nadd_header_above( classic, c(\" \" = 1, \"Sepal Length (cm)\" = 2))\n\nWarning in add_header_above(classic, c(` ` = 1, `Sepal Length (cm)` = 2)):\nPlease specify format in kable. kableExtra can customize either HTML or LaTeX\noutputs. See https://haozhu233.github.io/kableExtra/ for details.\n\n\n\nThe mean and variance in measured sepal length (in cm) for three species of Iris.\n\n\nSpecies\nAverage\nVariance\n\n\n\n\nsetosa\n5.006\n0.14368980\n\n\nversicolor\n5.936\n0.09846939\n\n\nvirginica\n6.588\n0.10400408"
  },
  {
    "objectID": "narrative_Factors.html#questions",
    "href": "narrative_Factors.html#questions",
    "title": "2  Factor Data",
    "section": "2.6 Questions",
    "text": "2.6 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas."
  },
  {
    "objectID": "narrative_Joins.html",
    "href": "narrative_Joins.html",
    "title": "3  Joins",
    "section": "",
    "text": "Rarely do we work on only one data.frame, particularly when we start working with complex data and data contained within relational databases. In these cases, data are factored into several tables (akin to data.frame objects) with entries that connect the information from one table to another. Consider the following example tables\nEach has a column I named Key and another with some data in it. In R they could be defined as:\nand"
  },
  {
    "objectID": "narrative_Joins.html#keys",
    "href": "narrative_Joins.html#keys",
    "title": "3  Joins",
    "section": "3.1 Keys",
    "text": "3.1 Keys\nAn important component of relational data are the keys. These are unique identifiers for a particular datum from a table. In each of these examples the variable (obviously named) Key is what is called a Primary Key because it uniquely identifies each row. You can verify this by counting the number of entries then filtering only for ones with 2 or more instances.\n\nlibrary( tidyverse )\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ndf.X %>%\n  count( Key ) %>%\n  filter( n > 1 )\n\n[1] Key n  \n<0 rows> (or 0-length row.names)\n\n\nNotice there is nothing here as each is unique.\n\nThe column Key is a Primary Key for the df.X data because it identifies a unique row in that table. In addition to a Primary Key we can have a Foreign Key when it is used to indicate data within a separate table. For example, if I am interested to see if the smallest value in df.X$X corresponds with the smallest value in df.Y$Y, then I will be using the Key form df.X representing max(X) to find the value of Y in df.Y and evaluate if it is max(Y). This means that df.X$Key is a Foreign Key as it points to a row in the df.Y data frame.\n\nThe keys are used to link together different tables."
  },
  {
    "objectID": "narrative_Joins.html#left-join",
    "href": "narrative_Joins.html#left-join",
    "title": "3  Joins",
    "section": "4.1 Left Join",
    "text": "4.1 Left Join\nA left join is one where all the data from the left data frame is in the result and the data whose keys in the right data frame are present in the left one are also included. Graphically, this leads to:\n\n\n\nleft join\n\n\nWhere in R we do this using the left_join() function.\n\ndf.X %>%\n  left_join( df.Y, by=\"Key\")\n\n  Key X  Y\n1   A 1 NA\n2   B 2 10\n3   C 3 11"
  },
  {
    "objectID": "narrative_Joins.html#right-join",
    "href": "narrative_Joins.html#right-join",
    "title": "3  Joins",
    "section": "4.2 Right Join",
    "text": "4.2 Right Join\nThe right join does the same thing but keeps all the keys in the right data table and has missing data where the key in the left one is not in the right one.\n\n\n\nRight Join\n\n\nThis is accomplished using the right_join() function.\n\ndf.X %>%\n  right_join( df.Y, by=\"Key\")\n\n  Key  X  Y\n1   B  2 10\n2   C  3 11\n3   D NA 12"
  },
  {
    "objectID": "narrative_Joins.html#full-or-outer-join",
    "href": "narrative_Joins.html#full-or-outer-join",
    "title": "3  Joins",
    "section": "4.3 Full (or Outer) Join",
    "text": "4.3 Full (or Outer) Join\nThis join is one where all the keys are retained adding missing data as necessary.\n\n\n\nOuter Join\n\n\n\ndf.X %>%\n  full_join( df.Y, by=\"Key\")\n\n  Key  X  Y\n1   A  1 NA\n2   B  2 10\n3   C  3 11\n4   D NA 12"
  },
  {
    "objectID": "narrative_Joins.html#inner-join",
    "href": "narrative_Joins.html#inner-join",
    "title": "3  Joins",
    "section": "4.4 Inner Join",
    "text": "4.4 Inner Join\nThe last one retains only those keys that are common in both.\n\n\n\nInner Join\n\n\n\ndf.X %>%\n  inner_join( df.Y, by=\"Key\")\n\n  Key X  Y\n1   B 2 10\n2   C 3 11"
  },
  {
    "objectID": "narrative_Joins.html#questions",
    "href": "narrative_Joins.html#questions",
    "title": "3  Joins",
    "section": "5.1 Questions",
    "text": "5.1 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas."
  },
  {
    "objectID": "narrative_Shapefiles.html",
    "href": "narrative_Shapefiles.html",
    "title": "4  Working with Shapefiles",
    "section": "",
    "text": "Linking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n✔ purrr   0.3.4      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nIn this topic, we will focus on lines and polygons. These are represented as sf objects, we can leverage a large amount of st_* functions to perform manipulations, and we can visualize them using either built-in routines or via ggplot (as expected)."
  },
  {
    "objectID": "narrative_Shapefiles.html#raw-data",
    "href": "narrative_Shapefiles.html#raw-data",
    "title": "4  Working with Shapefiles",
    "section": "4.1 Raw Data",
    "text": "4.1 Raw Data\nThe data for this are going to be represented by roads and development zones in Richmond, Virginia. These data are made available by the GIS Department of the City of Richmond. For this example, we will be loading these in as shapefiles.\nYou can load in shapefile data directly into R but we have to do a little work. First, we should understand that a shapefile is not an actual file, it is a collection of several files. They are often zipped up into a single archive.\nHere are two shape file archives that I have up on Github in the class repository.\n\nroads_url <- \"https://github.com/dyerlab/ENVS-Lectures/raw/master/data/Centerlines-shp.zip\"\ndistrict_url <- \"https://github.com/dyerlab/ENVS-Lectures/raw/master/data/Zoning_Districts-shp.zip\"\n\nWe can use R to download and unzip the file in the current data directory (n.b., you can do it using a browser as well). To use R you need to first download them (I’ve set eval=FALSE to the chuck so it is not redownloaded each time. Run it by hand using CTRL/CMD + Return).\n\ndownload.file( district_url , destfile = \"./Districts.zip\")\ndownload.file( roads_url, destfile =  \"./Roads.zip\")\n\nWe can unzip them now as:\n\nunzip(\"Districts.zip\")\nunzip(\"Roads.zip\")\n\nThese routines will expand the archives in the current directory.\nDepending upon how the archives were created, they may make a sub directory or just a pile of files in the same directory. For this example, the are one of each with the Zoning_Districts. set of files expanded in the current directory and the Roads expanded to a subfolder named Centerlines-shp.\n\nsystem( \"ls\" )"
  },
  {
    "objectID": "narrative_Shapefiles.html#lines",
    "href": "narrative_Shapefiles.html#lines",
    "title": "4  Working with Shapefiles",
    "section": "4.2 Lines",
    "text": "4.2 Lines\nWe’ve covered points and now if we put them together in a sequence, we get lines. They are taken in the order given, just like when we were plotting polygons using geom_polygon(). Instead of loading these in manually, I’m going to load in the shapefile with the roads. To load in shapefiles, we use the st_read() function and pass it the .shp file.\n\nroads <- st_read( \"Centerlines-shp/tran_Carriageway.shp\" ) \n\nReading layer `tran_Carriageway' from data source \n  `/Users/Endru/Desktop/Enviro Data Literacy/DataLit_narratives/Centerlines-shp/tran_Carriageway.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 29081 features and 25 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 11734060 ymin: 3682790 xmax: 11817490 ymax: 3751927\nProjected CRS: NAD83 / Virginia South (ftUS)\n\nnames( roads )\n\n [1] \"FID\"        \"Carriagewa\" \"AssetID\"    \"StreetType\" \"Functional\"\n [6] \"FIPS\"       \"LeftFromAd\" \"LeftToAddr\" \"RightFromA\" \"RightToAdd\"\n[11] \"PrefixDire\" \"ProperName\" \"SuffixType\" \"SuffixDire\" \"FullName\"  \n[16] \"RouteName\"  \"OneWay\"     \"PostedSpee\" \"CADRouteSp\" \"CreatedBy\" \n[21] \"CreatedDat\" \"EditBy\"     \"EditDate\"   \"GlobalID\"   \"SHAPE_Leng\"\n[26] \"geometry\"  \n\n\nWe can clean it up a bit by removing the extraneous columns.\n\nroads %>%\n  select(-CreatedBy,\n         -CreatedDat,\n         -EditBy,\n         -EditDate) %>%\n  select( FIPS, AssetID, StreetType, Functional, FullName, OneWay, geometry ) -> roads\nroads\n\nSimple feature collection with 29081 features and 6 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 11734060 ymin: 3682790 xmax: 11817490 ymax: 3751927\nProjected CRS: NAD83 / Virginia South (ftUS)\nFirst 10 features:\n   FIPS AssetID StreetType Functional      FullName OneWay\n1   760       2  Secondary      Local     Sauer Ave   <NA>\n2   760       3  Secondary      Local     Sauer Ave   <NA>\n3   760      89  Secondary      Local   Amherst Ave   <NA>\n4   760      91  Secondary      Local     Corbin St   <NA>\n5   760      92  Secondary      Local    Piney Road   <NA>\n6   760      93  Secondary      Local     Corbin St   <NA>\n7   760      94  Secondary      Local Old Brook Cir   <NA>\n8   760      99  Secondary  Collector  Fauquier Ave     FT\n9   760     104  Secondary      Local  Nottoway Ave   <NA>\n10  760     107  Secondary      Local     Corbin St   <NA>\n                         geometry\n1  LINESTRING (11775968 373330...\n2  LINESTRING (11775997 373334...\n3  LINESTRING (11785407 374003...\n4  LINESTRING (11789753 374015...\n5  LINESTRING (11788684 373991...\n6  LINESTRING (11789640 373986...\n7  LINESTRING (11787930 373982...\n8  LINESTRING (11785621 373921...\n9  LINESTRING (11784473 373936...\n10 LINESTRING (11789514 373955...\n\n\nYou can see that the geometry object is a LINESTRING (in sf terms). We can see the coordinates for one of these (say Dwyer St), by conveting the geometry object to a Well Know Text (WKT) version representing the sequence of points.\nFor any particular street, say Three Chopt Road in Richmond, we can filter out the rows of this for each LINESTRING object.\n\nroads %>% \n  filter( FullName == \"Three Chopt Road\") -> three_chopt\nthree_chopt\n\nSimple feature collection with 65 features and 6 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 11755430 ymin: 3732239 xmax: 11766160 ymax: 3744563\nProjected CRS: NAD83 / Virginia South (ftUS)\nFirst 10 features:\n   FIPS AssetID StreetType     Functional         FullName OneWay\n1   760    8868     Artery Minor Arterial Three Chopt Road     FT\n2   760    8870     Artery Minor Arterial Three Chopt Road     FT\n3   760   10053     Artery Minor Arterial Three Chopt Road     TF\n4   760   10054     Artery Minor Arterial Three Chopt Road     TF\n5   760   10055     Artery Minor Arterial Three Chopt Road     FT\n6   760   10056     Artery Minor Arterial Three Chopt Road     FT\n7   760   10057     Artery Minor Arterial Three Chopt Road   <NA>\n8   760   10058     Artery Minor Arterial Three Chopt Road   <NA>\n9   760   12433     Artery Minor Arterial Three Chopt Road   <NA>\n10  760   12440     Artery Minor Arterial Three Chopt Road   <NA>\n                         geometry\n1  LINESTRING (11763416 373910...\n2  LINESTRING (11763405 373865...\n3  LINESTRING (11763466 374021...\n4  LINESTRING (11763452 374026...\n5  LINESTRING (11763466 374021...\n6  LINESTRING (11763483 374024...\n7  LINESTRING (11763460 373995...\n8  LINESTRING (11763449 373956...\n9  LINESTRING (11765211 373462...\n10 LINESTRING (11765747 373355...\n\n\nThis one has 65 elements, each of which is created by a sequence of points. We can loop through them and print out the coordinates in textual format as:\n\nfor( i in 1:nrow(three_chopt) ) {\n  geo <- three_chopt$geometry[i]\n  cat( i, st_as_text( geo ), \"\\n\") \n}\n\n1 LINESTRING (11763416 3739109, 11763452 3739376) \n2 LINESTRING (11763405 3738655, 11763403 3738666, 11763398 3738687, 11763386 3738761, 11763382 3738807, 11763383 3738849, 11763385 3738879, 11763392 3738922, 11763395 3738955, 11763414 3739084, 11763416 3739109) \n3 LINESTRING (11763466 3740210, 11763459 3740241, 11763452 3740269) \n4 LINESTRING (11763452 3740269, 11763455 3740306, 11763478 3740532) \n5 LINESTRING (11763466 3740210, 11763475 3740227, 11763483 3740243) \n6 LINESTRING (11763483 3740243, 11763487 3740298, 11763508 3740495) \n7 LINESTRING (11763460 3739957, 11763460 3739970, 11763462 3740051, 11763464 3740132, 11763466 3740210) \n8 LINESTRING (11763449 3739565, 11763451 3739646, 11763454 3739727, 11763456 3739813, 11763458 3739889, 11763460 3739957) \n9 LINESTRING (11765211 3734622, 11765195 3734652, 11765182 3734682, 11765169 3734713, 11765159 3734744, 11765145 3734793, 11765133 3734842, 11765123 3734892, 11765114 3734955, 11765103 3735018, 11765102 3735024, 11765096 3735051, 11765089 3735077, 11765079 3735102) \n10 LINESTRING (11765747 3733557, 11765743 3733573) \n11 LINESTRING (11765743 3733573, 11765625 3734022, 11765619 3734041, 11765612 3734061, 11765603 3734079) \n12 LINESTRING (11765603 3734079, 11765596 3734095, 11765587 3734109) \n13 LINESTRING (11765785 3733407, 11765751 3733540) \n14 LINESTRING (11765751 3733540, 11765747 3733557) \n15 LINESTRING (11765079 3735102, 11765079 3735131, 11765078 3735159, 11765075 3735187, 11765051 3735355) \n16 LINESTRING (11765587 3734109, 11765578 3734122, 11765569 3734135, 11765471 3734266, 11765356 3734419, 11765251 3734560) \n17 LINESTRING (11765251 3734560, 11765230 3734591, 11765211 3734622) \n18 LINESTRING (11763934 3736816, 11763898 3736854, 11763863 3736893, 11763829 3736934, 11763798 3736975, 11763768 3737018, 11763746 3737052, 11763726 3737087, 11763707 3737124) \n19 LINESTRING (11763707 3737124, 11763690 3737162, 11763674 3737202, 11763661 3737242) \n20 LINESTRING (11766160 3732239, 11766154 3732261, 11766146 3732281, 11766137 3732301, 11766125 3732320, 11766111 3732338) \n21 LINESTRING (11766111 3732338, 11766093 3732359, 11766077 3732381, 11766063 3732405, 11766051 3732429, 11766040 3732454, 11765967 3732710, 11765954 3732756) \n22 LINESTRING (11765954 3732756, 11765900 3732959) \n23 LINESTRING (11765900 3732959, 11765785 3733407) \n24 LINESTRING (11763442 3738419, 11763392 3738656) \n25 LINESTRING (11763661 3737242, 11763641 3737323, 11763560 3737754, 11763499 3738117, 11763442 3738419) \n26 LINESTRING (11765051 3735355, 11765040 3735477, 11765027 3735603, 11765006 3735720) \n27 LINESTRING (11765006 3735720, 11764995 3735768, 11764982 3735815, 11764967 3735862, 11764950 3735908, 11764932 3735953, 11764911 3735997, 11764882 3736048, 11764852 3736098, 11764826 3736138, 11764798 3736178, 11764769 3736216, 11764739 3736254) \n28 LINESTRING (11764137 3736666, 11764136 3736666, 11764093 3736693, 11764051 3736721, 11764011 3736751, 11763972 3736783, 11763934 3736816) \n29 LINESTRING (11764739 3736254, 11764665 3736336, 11764642 3736363, 11764617 3736388, 11764591 3736412, 11764564 3736434, 11764540 3736451, 11764516 3736467, 11764490 3736482, 11764464 3736495, 11764457 3736499, 11764390 3736532, 11764273 3736592, 11764227 3736615, 11764182 3736639, 11764137 3736666) \n30 LINESTRING (11765310 3734586, 11765295 3734599, 11765282 3734614, 11765268 3734634, 11765254 3734654, 11765242 3734675, 11765232 3734696, 11765219 3734727, 11765208 3734758, 11765199 3734789, 11765190 3734821, 11765177 3734889, 11765162 3734957, 11765160 3734976, 11765156 3734993, 11765150 3735011, 11765142 3735028, 11765133 3735043, 11765121 3735060, 11765108 3735075, 11765094 3735089, 11765079 3735102) \n31 LINESTRING (11765857 3733581, 11765848 3733588, 11765847 3733588, 11765836 3733599, 11765825 3733611, 11765817 3733624, 11765809 3733637, 11765804 3733652, 11765749 3733864, 11765694 3734088, 11765689 3734103, 11765683 3734118, 11765675 3734132) \n32 LINESTRING (11765675 3734132, 11765636 3734183, 11765359 3734547, 11765344 3734561, 11765327 3734574, 11765310 3734586) \n33 LINESTRING (11759671 3743060, 11759743 3743022, 11759962 3742885) \n34 LINESTRING (11759962 3742885, 11760198 3742743, 11760303 3742691, 11760432 3742645, 11760506 3742626, 11760570 3742617) \n35 LINESTRING (11760570 3742617, 11760922 3742570) \n36 LINESTRING (11760922 3742570, 11761128 3742538, 11761301 3742505) \n37 LINESTRING (11761301 3742505, 11761737 3742422) \n38 LINESTRING (11761737 3742422, 11761973 3742378, 11762064 3742355, 11762163 3742318, 11762234 3742279) \n39 LINESTRING (11762234 3742279, 11762345 3742202, 11762581 3742010) \n40 LINESTRING (11762581 3742010, 11762798 3741834) \n41 LINESTRING (11756794 3744048, 11757219 3743916, 11757442 3743857, 11757585 3743811) \n42 LINESTRING (11757585 3743811, 11757919 3743694) \n43 LINESTRING (11757919 3743694, 11758226 3743587) \n44 LINESTRING (11758226 3743587, 11758589 3743460) \n45 LINESTRING (11758589 3743460, 11758970 3743326) \n46 LINESTRING (11759295 3743234, 11759313 3743227) \n47 LINESTRING (11759313 3743227, 11759332 3743220) \n48 LINESTRING (11759332 3743220, 11759478 3743169, 11759644 3743095, 11759671 3743060) \n49 LINESTRING (11759280 3743196, 11759299 3743190) \n50 LINESTRING (11759299 3743190, 11759300 3743190, 11759318 3743183) \n51 LINESTRING (11759318 3743183, 11759463 3743132, 11759631 3743056, 11759671 3743060) \n52 LINESTRING (11755429 3744542, 11755434 3744537, 11755501 3744480, 11755502 3744479, 11755574 3744429, 11755576 3744428, 11755652 3744386, 11755654 3744385, 11755734 3744350, 11755736 3744349, 11756446 3744138, 11756739 3744045, 11756794 3744048) \n53 LINESTRING (11755466 3744563, 11755526 3744511, 11755596 3744463, 11755671 3744421, 11755749 3744387, 11756458 3744176, 11756458 3744176, 11756750 3744084, 11756794 3744048) \n54 LINESTRING (11762798 3741834, 11763253 3741478, 11763350 3741382) \n55 LINESTRING (11763350 3741382, 11763364 3741367) \n56 LINESTRING (11758970 3743326, 11759023 3743329, 11759295 3743234) \n57 LINESTRING (11758970 3743326, 11759009 3743291, 11759280 3743196) \n58 LINESTRING (11763508 3740495, 11763505 3740642) \n59 LINESTRING (11763505 3740642, 11763509 3740676, 11763510 3740774, 11763500 3740870, 11763471 3741028) \n60 LINESTRING (11763478 3740532, 11763505 3740642) \n61 LINESTRING (11763441 3739375, 11763446 3739407, 11763449 3739565) \n62 LINESTRING (11763393 3739110, 11763413 3739268, 11763413 3739284, 11763428 3739375) \n63 LINESTRING (11763383 3738657, 11763380 3738666, 11763373 3738704, 11763362 3738777, 11763358 3738817, 11763359 3738854, 11763361 3738885, 11763365 3738920, 11763393 3739110) \n64 LINESTRING (11763471 3741028, 11763438 3741210, 11763427 3741246, 11763398 3741312, 11763376 3741348) \n65 LINESTRING (11763376 3741348, 11763364 3741367) \n\n\nWe can then plot this using the built-in plot commands as:\n\nplot( three_chopt[\"StreetType\"] )\n\n\n\n\nOr using ggplot as:\n\nggplot( three_chopt ) + \n  geom_sf() + \n  coord_sf()"
  },
  {
    "objectID": "narrative_Shapefiles.html#polygons",
    "href": "narrative_Shapefiles.html#polygons",
    "title": "4  Working with Shapefiles",
    "section": "4.3 Polygons",
    "text": "4.3 Polygons\nPolygons are simply lines whose first and last point are the same (e.g., they close upon themselves). We can create these de novo\n\n4.3.1 Polygons from Data Frames\nAs a first approximation, we can grab polygon data from ggplot itself. Here I pull in the data.frame representing the counties of Virginia.\n\nlibrary( maps )\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nmap_data( \"county\", \"virginia\") %>%\n  select( Longitude = long,\n          Latitude = lat,\n          group,\n          County = subregion) -> va_counties\nhead( va_counties )\n\n  Longitude Latitude group   County\n1 -75.27519 38.03867     1 accomack\n2 -75.21790 38.02721     1 accomack\n3 -75.21790 38.02721     1 accomack\n4 -75.24655 37.99283     1 accomack\n5 -75.30384 37.94127     1 accomack\n6 -75.31530 37.92981     1 accomack\n\n\nTo get an idea of what theses data represent visually, let’s first plot it as a geom_point() object. This wil show you where all the coordinates are located (just not the connecting lines).\n\nggplot( va_counties, aes( Longitude, Latitude) ) + \n  geom_point( size=0.25 ) + \n  coord_quickmap()\n\n\n\n\n\nggplot( va_counties, aes( Longitude, Latitude) ) + \n  geom_polygon( aes( group=group ),\n                fill=\"grey80\",\n                color = \"black\", \n                size = 0.25) + \n  coord_quickmap()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nWhat is hidden here is the complexity of the the points themselves. Each county is identified by a group in the data.frame\nIf we look at a particular county, it may be a bit more informative on how these things are consturcted. Here are the points (in red) and the underlying connecting lines creating the polygon (in grey).\n\nva_counties %>%\n  filter( County %in%  c(\"hanover\",\"henrico\") ) %>%\n  ggplot( aes(Longitude, Latitude) ) + \n  geom_polygon( aes( fill = County), alpha=0.1 ) +\n  geom_point( aes( color = County) ) +\n  coord_quickmap()\n\n\n\n\nNotice that the points on the border are repeated in both County == \"hanover\" and County == \"henrico\".\n\n\n4.3.2 Polygons from Shapefiles\nWe can also load these in from shapefiles. In the Richmond GIS data, we have Zoning District data. We can unzip them in the current directory as before.\n\nunzip( \"./Districts.zip\")\n\nAnd in this case, it simply expands all the files in the current directory as a set of files named Zoning_Districts.*.\n\nsystem(\"ls -al Zoning*\")\n\nTo load it in, we read the shapefile (.shp) from the local directory.\n\ndistricts <- st_read( \"Zoning_Districts.shp\" )\n\nReading layer `Zoning_Districts' from data source \n  `/Users/Endru/Desktop/Enviro Data Literacy/DataLit_narratives/Zoning_Districts.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 634 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 11743500 ymin: 3687944 xmax: 11806060 ymax: 3744741\nProjected CRS: NAD83 / Virginia South (ftUS)\n\nclass( districts )\n\n[1] \"sf\"         \"data.frame\"\n\n\nThis has a lot of columns of information.\n\nnames( districts )\n\n [1] \"OBJECTID\"   \"Name\"       \"Ordinance\"  \"OrdinanceP\" \"Conditiona\"\n [6] \"AdoptionDa\" \"Comment\"    \"CreatedBy\"  \"CreatedDat\" \"EditBy\"    \n[11] \"EditDate\"   \"GlobalID\"   \"Shape__Are\" \"Shape__Len\" \"geometry\"  \n\n\n\nsummary( districts )\n\n    OBJECTID          Name            Ordinance          OrdinanceP       \n Min.   :   1.0   Length:634         Length:634         Length:634        \n 1st Qu.: 162.2   Class :character   Class :character   Class :character  \n Median : 324.5   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 389.6                                                           \n 3rd Qu.: 486.8                                                           \n Max.   :2677.0                                                           \n  Conditiona          AdoptionDa           Comment           CreatedBy        \n Length:634         Min.   :2000-01-01   Length:634         Length:634        \n Class :character   1st Qu.:2000-01-01   Class :character   Class :character  \n Mode  :character   Median :2000-01-01   Mode  :character   Mode  :character  \n                    Mean   :2004-01-20                                        \n                    3rd Qu.:2007-09-10                                        \n                    Max.   :2020-07-27                                        \n   CreatedDat            EditBy             EditDate         \n Min.   :2020-08-24   Length:634         Min.   :2020-08-24  \n 1st Qu.:2020-08-24   Class :character   1st Qu.:2020-08-24  \n Median :2020-08-24   Mode  :character   Median :2020-08-24  \n Mean   :2020-08-24                      Mean   :2020-08-24  \n 3rd Qu.:2020-08-24                      3rd Qu.:2020-08-24  \n Max.   :2020-08-24                      Max.   :2020-08-24  \n   GlobalID           Shape__Are          Shape__Len                geometry  \n Length:634         Min.   :     2823   Min.   :   213.4   MULTIPOLYGON :634  \n Class :character   1st Qu.:    71070   1st Qu.:  1232.3   epsg:2284    :  0  \n Mode  :character   Median :   258852   Median :  2552.3   +proj=lcc ...:  0  \n                    Mean   :  2749033   Mean   :  6265.9                      \n                    3rd Qu.:  1175317   3rd Qu.:  6166.8                      \n                    Max.   :171812574   Max.   :111874.1                      \n\n\nMore importantly, we can look at the raw data and see the other meta data.\n\nhead(districts, n=2)\n\nSimple feature collection with 2 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 11773600 ymin: 3730159 xmax: 11789510 ymax: 3731016\nProjected CRS: NAD83 / Virginia South (ftUS)\n  OBJECTID Name Ordinance OrdinanceP Conditiona AdoptionDa Comment\n1        1 RO-2      <NA>       <NA>         No 2000-01-01    <NA>\n2        2  B-2      <NA>       <NA>         No 2000-01-01    <NA>\n           CreatedBy CreatedDat             EditBy   EditDate\n1 richard.morton_cor 2020-08-24 richard.morton_cor 2020-08-24\n2 richard.morton_cor 2020-08-24 richard.morton_cor 2020-08-24\n                              GlobalID Shape__Are Shape__Len\n1 334799f0-fe38-46bf-97c2-260f5a036559   60150.29   983.6815\n2 558df9cd-4f9c-4248-a689-bc2d9c79d060   56987.01   971.8832\n                        geometry\n1 MULTIPOLYGON (((11773598 37...\n2 MULTIPOLYGON (((11789222 37...\n\n\nThe whole thing looks like this (I’ll use the area of each polygon as the fill color).\n\nplot( districts[\"Shape__Are\"], axes=TRUE )\n\n\n\n\nNotice it is in CRS = NAD83/Virginia South (ftUS), which if we look at epsg.io and search for it relates to EPGS=32147. Let’s do some pre-processing1:\n- Put it in Lat/Lon for simplicity\n- Drop some of the unnecessary columns of data in the shapefile. - Crop to the VCU/Fan area (I went to google earth and found the bounding box and then just added it here so I had to make it lat/lon then crop then change it back).\n\ndistricts %>% \n  select( OBJECTID, \n          Name, \n          GlobalID, \n          Area = Shape__Are,\n          geometry) -> districts\nhead( districts )\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 11772310 ymin: 3727332 xmax: 11794670 ymax: 3731016\nProjected CRS: NAD83 / Virginia South (ftUS)\n  OBJECTID Name                             GlobalID      Area\n1        1 RO-2 334799f0-fe38-46bf-97c2-260f5a036559  60150.29\n2        2  B-2 558df9cd-4f9c-4248-a689-bc2d9c79d060  56987.01\n3        3  R-6 8d731cd3-7cfb-41d4-9545-44f1055515b3  93826.03\n4        4  B-1 f4fb1283-03ff-41e7-b5ed-3cf6e80c2e9b  17526.31\n5        5  B-1 f1305477-4e71-463c-a202-332971d8c5e1  33261.30\n6        6 RO-1 65e43734-9728-4241-921d-c657137dae0a 132773.19\n                        geometry\n1 MULTIPOLYGON (((11773598 37...\n2 MULTIPOLYGON (((11789222 37...\n3 MULTIPOLYGON (((11774598 37...\n4 MULTIPOLYGON (((11794468 37...\n5 MULTIPOLYGON (((11781126 37...\n6 MULTIPOLYGON (((11772306 37...\n\n\nAnd we can plot it normally using plot() for sf objects. Each row is a MULTIPOLYGON object.\n\ndistricts %>%\n  filter( OBJECTID == 368 ) %>%\n  st_buffer(dist = 1500) %>%\n  st_bbox() -> fan_bbox\ndistricts %>%\n  st_crop( fan_bbox ) -> theFan \n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\nplot( theFan[\"Name\"] )\n\n\n\n\nOr as a ggplot() object (notice how it converts to lat/lon when plotting),\n\nggplot( theFan ) + \n  geom_sf( aes( fill=Name ) ) + \n  coord_sf() \n\n\n\n\nLet’s go grab a key to those zoning types. I’ve uploaded a csv file with a translation. Here I left_join() with that new file that is read in dynamically2.\n\nzone_url <- \"https://raw.githubusercontent.com/dyerlab/ENVS-Lectures/master/data/DistrictCodes.csv\"\ntheFan %>%\n  left_join( read_csv( zone_url ),\n             by=\"Name\") %>%\n  mutate( Category = factor( Category) ) %>%\n  select( OBJECTID, \n          Name, \n          Category, \n          everything() )  -> theFan\n\nRows: 27 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Name, Category\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot( theFan ) +\n  geom_sf( aes( fill=Category)) +\n  scale_fill_brewer( type=\"qual\", \n                     palette = \"Set3\")"
  },
  {
    "objectID": "narrative_Shapefiles.html#operations",
    "href": "narrative_Shapefiles.html#operations",
    "title": "4  Working with Shapefiles",
    "section": "4.4 Operations",
    "text": "4.4 Operations\nSo we will close this out by looking at a few different operations that we can use for polygons. First, I’m going to load in the road shapefile (that was named by some random sequence of letters) and reproject it.\n\nhead( roads, n=3)\n\nSimple feature collection with 3 features and 6 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 11775970 ymin: 3733301 xmax: 11786050 ymax: 3740059\nProjected CRS: NAD83 / Virginia South (ftUS)\n  FIPS AssetID StreetType Functional    FullName OneWay\n1  760       2  Secondary      Local   Sauer Ave   <NA>\n2  760       3  Secondary      Local   Sauer Ave   <NA>\n3  760      89  Secondary      Local Amherst Ave   <NA>\n                        geometry\n1 LINESTRING (11775968 373330...\n2 LINESTRING (11775997 373334...\n3 LINESTRING (11785407 374003...\n\n\n\nplot( theFan$geometry, lwd=2 )\nfanRoads <- st_crop( roads, st_bbox( theFan ))\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\nplot( fanRoads$geometry, col=\"blue\", cex=0.5, add=TRUE )\n\n\n\n\nLet’s isolate one of the main polygons in theFan data set. The target one below is indicated by OBJECTID=368.\n\ntheFan %>%\n  mutate( Target = ifelse( OBJECTID == 368, \n                           TRUE, \n                           FALSE) ) -> theFan\ntheFan %>%\n  ggplot() + \n  geom_sf( aes(fill=Target) ) + \n  geom_sf_text( aes(label=OBJECTID), size=3 ) +\n  coord_sf()"
  },
  {
    "objectID": "narrative_Shapefiles.html#spatial-joins",
    "href": "narrative_Shapefiles.html#spatial-joins",
    "title": "4  Working with Shapefiles",
    "section": "4.5 Spatial Joins",
    "text": "4.5 Spatial Joins\n\nnames( theFan )\n\n[1] \"OBJECTID\" \"Name\"     \"Category\" \"GlobalID\" \"Area\"     \"geometry\" \"Target\"  \n\nnames( fanRoads )\n\n[1] \"FIPS\"       \"AssetID\"    \"StreetType\" \"Functional\" \"FullName\"  \n[6] \"OneWay\"     \"geometry\"  \n\n\nWe can use spatial joins to select features either directly. Here I’ll use the target polygon in theFan\n\ntarget <- theFan[ theFan$OBJECTID == 368, ]\ntarget\n\nSimple feature collection with 1 feature and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 11780610 ymin: 3724146 xmax: 11786260 ymax: 3729483\nProjected CRS: NAD83 / Virginia South (ftUS)\n   OBJECTID Name    Category                             GlobalID     Area\n39      368  R-6 Residential d9882dad-2625-44e7-a170-3f1425450679 13040977\n                         geometry Target\n39 POLYGON ((11785188 3726513,...   TRUE\n\n\nAnd then add an attribute to the data.frame if each multipolygon intersects that polygon.\n\nfanRoads %>%\n  mutate( OnTarget = st_intersects( fanRoads,\n                                    target, \n                                    sparse = FALSE ) ) -> fanRoads\nsummary( fanRoads$OnTarget )\n\n     V1         \n Mode :logical  \n FALSE:1567     \n TRUE :553      \n\n\nWe can get the names of these road using normal dplyr routines,\n\nfanRoads %>%\n  filter( st_intersects( fanRoads,\n                         target, \n                         sparse = FALSE ) == TRUE ) %>%\n  as_data_frame() %>%\n  select( `Street Name` = FullName ) %>%\n  arrange( `Street Name`) %>%\n  unique() \n\nWarning: `as_data_frame()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n# A tibble: 39 × 1\n   `Street Name` \n   <chr>         \n 1 Allison St    \n 2 Birch St      \n 3 Boyd St       \n 4 Floyd Ave     \n 5 Grove Ave     \n 6 Hanover Ave   \n 7 Kensington Ave\n 8 Lombardy Pl   \n 9 Madumbie Lane \n10 Monument Ave  \n# … with 29 more rows\n\n\nAnd we can plot them as:\n\nfanRoads %>%\n  filter( OnTarget==TRUE ) %>%\n  ggplot() +\n  geom_sf( aes( fill = Target ), data=theFan ) +\n  geom_sf( color=\"green\" ) + \n  scale_fill_manual( values=c(\"grey90\",\"dodgerblue3\"))\n\n\n\n\nGo check out the sf cheatsheet for more geospatial joins and options."
  }
]